{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pandasai import Agent\n",
    "\n",
    "# Sample DataFrame\n",
    "epl_dataframe = pd.read_csv(\"data.csv\")\n",
    "\n",
    "display(epl_dataframe)\n",
    "# By default, unless you choose a different LLM, it will use BambooLLM.\n",
    "# You can get your free API key signing up at https://pandabi.ai (you can also configure it in your .env file)\n",
    "os.environ[\"PANDASAI_API_KEY\"] = \"$2a$10$Acl/GiigqUBVrkIto70yQOgGCTGxDMZcdVkws/q12g4O54p3y55oW\"\n",
    "\n",
    "agent = Agent(epl_dataframe)\n",
    "agent.chat('Which home or away teams are most likely to win?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.chat(\"Can you construct the graph of HomeWinOdds vs DrawOdds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cox-Ingersoll-Ross (CIR) Model parameters\n",
    "K = 0.9           # Speed of mean reversion\n",
    "long_mean = 4     # Long-term mean\n",
    "variance = 3      # Volatility\n",
    "\n",
    "N = 100  # Number of simulations\n",
    "T = 1    # Total time (1 year)\n",
    "M = 400  # Number of time steps\n",
    "d_t = T / M  # Time step size\n",
    "\n",
    "# Initialize the simulation matrix\n",
    "corner_sim = np.zeros((M, N))\n",
    "initial_value = 4  # Initial value for each simulation\n",
    "corner_sim[0, :] = initial_value\n",
    "\n",
    "# Generate all random changes at once\n",
    "random_changes = np.sqrt(d_t) * np.random.normal(0, 1, (M-1, N))\n",
    "\n",
    "# Vectorized simulation of the CIR process\n",
    "for t in range(1, M):\n",
    "    corner_sim[t, :] = (corner_sim[t-1, :] +\n",
    "                        K * (long_mean - corner_sim[t-1, :]) * d_t +\n",
    "                        variance * np.sqrt(np.maximum(corner_sim[t-1, :], 0)) * random_changes[t-1, :])\n",
    "\n",
    "# Plot the first 10 simulations\n",
    "plt.plot(corner_sim[:, :10])\n",
    "plt.ylabel(\"Value of Corners\")\n",
    "plt.xlabel(\"Days\")\n",
    "plt.title(\"Monte Carlo Simulation of Corners Using CIR Model (Vectorized)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def heston_model_simulation(S0, v0, rho, kappa, theta, sigma, T, N, M):\n",
    "    dt = T / N\n",
    "    mu = np.array([0, 0])\n",
    "    cov = np.array([[1, rho],\n",
    "                    [rho, 1]])\n",
    "\n",
    "    S = np.full(shape=(N + 1, M), fill_value=S0)\n",
    "    v = np.full(shape=(N + 1, M), fill_value=v0)\n",
    "    m = np.full(shape=(N + 1, M), fill_value=0.2)\n",
    "\n",
    "    Z = np.random.multivariate_normal(mu, cov, (N, M))\n",
    "    for i in range(1, N + 1):\n",
    "        S[i] = S[i - 1] * np.exp((r - q - 0.5 * v[i - 1]) * dt + np.sqrt(v[i - 1] * dt) * Z[i - 1, :, 0])\n",
    "        v[i] = np.maximum(v[i - 1] + kappa * (theta - v[i - 1]) * dt + sigma * np.sqrt(v[i - 1] * dt) * Z[i - 1, :, 1],\n",
    "                          0)\n",
    "        m[i] = m[i - 1]*np.exp(-theta * Z[i - 1, :, 0])\n",
    "\n",
    "    return S, v, m\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    T = 1\n",
    "    r = 0.01\n",
    "    q = 0.02\n",
    "    S0 = 2300\n",
    "    kappa = 0.7\n",
    "    rho_a = -0.60\n",
    "    M = 5\n",
    "    N = 252\n",
    "    v0 = 0.20 ** 2\n",
    "    theta = 0.15 ** 2\n",
    "    sigma = 0.5\n",
    "\n",
    "    S_n, v_n, M_n = heston_model_simulation(S0, v0, rho_a, kappa, theta, sigma, T, N, M)\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 5))\n",
    "    time = np.linspace(0, T, N + 1)\n",
    "    ax1.plot(time, S_n)\n",
    "    ax1.set_title('Asset Prices')\n",
    "    ax1.set_xlabel('Time')\n",
    "    ax1.set_ylabel('Asset Prices')\n",
    "    ax2.plot(time, v_n)\n",
    "    ax2.set_title('Volatility')\n",
    "    ax2.set_xlabel('Time')\n",
    "    ax2.set_ylabel('Volatility')\n",
    "    ax3.plot(time, M_n)\n",
    "    ax3.set_title('Risk Price')\n",
    "    ax3.set_xlabel('Time')\n",
    "    ax3.set_ylabel('Risk Price')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "start_date = \"2017-01-03\"\n",
    "end_date = \"2019-10-01\"\n",
    "# Define tickers for US Treasury yields\n",
    "treasury_tickers = ['^IRX', '^FVX', '^TNX', '^TYX']\n",
    "\n",
    "# Fetch historical data (e.g., for the last year)\n",
    "treasury_data = yf.download(treasury_tickers, start=start_date, end=end_date)\n",
    "\n",
    "# Display historical closing prices for each tenor\n",
    "print(treasury_data['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the closing yields\n",
    "treasury_data['Close'].plot(figsize=(10, 6), title=\"U.S. Treasury Yields Across Tenors\")\n",
    "plt.ylabel(\"Yield (%)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = treasury_data['Close'].loc[\"2019-09-03\"].to_list()  # Yields for each tenor on that date\n",
    "X = ['^IRX', '^FVX', '^TNX', '^TYX']  # Tenors: 3-month, 5-year, 10-year, 30-year\n",
    "\n",
    "# Plot yields for the specific date across tenors\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(X, Y, marker='o', color='b', linestyle='-', linewidth=2, markersize=8)  # Line plot with markers\n",
    "plt.title(f\"U.S. Treasury Yields on {start_date}\")\n",
    "plt.xlabel(\"Tenors\")\n",
    "plt.ylabel(\"Yield (%)\")\n",
    "plt.grid(True)  # Optional: add gridlines for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "time_days = datetime.strptime(\"2027-07-01\", \"%Y-%m-%d\") - datetime.now()\n",
    "time_days = time_days.days / 365\n",
    "last_yield= 2.809/100\n",
    "fv = 100\n",
    "coupon_rate = 0.375/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_coupon(coupon_rate, face_value, time_in_years, yield_value, exponentially=False):\n",
    "    coupon_values = []\n",
    "    \n",
    "    # Using numpy.arange to create a range of float values\n",
    "    time_discount = 0.0\n",
    "    while time_discount <= time_in_years:\n",
    "        coupon_values.append(discounter(coupon_rate * face_value, yield_value, time_discount, exponentially))\n",
    "        print(f\"Time Discount: {time_discount}, Coupon Value: {coupon_values[-1]}\")\n",
    "        time_discount += 0.25  # Increment by 0.25 years\n",
    "\n",
    "    return coupon_values \n",
    "\n",
    "def discounter(value, rate, time, exponentially=False):\n",
    "    if exponentially:\n",
    "        return value*np.exp(-rate*time)\n",
    "    return value/np.power(rate+1, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_of_coupons = calculate_coupon(coupon_rate, fv, time_days, last_yield, True)\n",
    "pv_of_principal = discounter(fv, last_yield, time_days, True)\n",
    "\n",
    "print(f\"PV: {pv_of_principal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "# Parameters\n",
    "start_date = \"2015-07-01\"\n",
    "end_date = \"2023-12-31\"\n",
    "n_tenors = 20\n",
    "tenors = np.linspace(3, 60, n_tenors, dtype=int)  # Tenors from 3 to 60 months\n",
    "\n",
    "# Generate date range\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='B')  # Business days\n",
    "\n",
    "# Initialize DataFrame\n",
    "data = []\n",
    "\n",
    "# Populate dataset\n",
    "for date in date_range:\n",
    "    for tenor in tenors:\n",
    "        if tenor == 3 and date < pd.to_datetime(\"2022-03-01\"):\n",
    "            # Use Eurodollar Futures data before March 2022 for 3-month tenor\n",
    "            contract_type = \"Eurodollar\"\n",
    "            price_variation = np.random.normal(0, 0.02)  # Example price variation\n",
    "            order_flow = np.random.normal(0, 100)  # Example order flow\n",
    "        else:\n",
    "            # Use SOFR Futures data after March 2022 or for other tenors\n",
    "            contract_type = \"SOFR\"\n",
    "            price_variation = np.random.normal(0, 0.015)  # Example price variation\n",
    "            order_flow = np.random.normal(0, 80)  # Example order flow\n",
    "\n",
    "        # Append to data\n",
    "        data.append([date, tenor, contract_type, price_variation, order_flow])\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"Date\", \"Tenor (Months)\", \"Contract Type\", \"Price Variation\", \"Net Order Flow\"])\n",
    "\n",
    "# Display sample\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "FORMAT = \"%d/%m/%Y\"\n",
    "\n",
    "def is_business_day(date, holidays=[]):\n",
    "    date = pd.Timestamp(date)\n",
    "    return (date.weekday() < 5) and (date not in holidays)\n",
    "\n",
    "def next_business_day(date):\n",
    "    date = pd.Timestamp(date)\n",
    "    next_day = date + pd.offsets.BDay(1)\n",
    "    return next_day\n",
    "\n",
    "def __create_days_vector(start_date: datetime.date, settlement_date: datetime.date):\n",
    "    current_date = start_date\n",
    "    days_vector = []\n",
    "    while current_date < settlement_date:\n",
    "        if is_business_day(current_date):\n",
    "            next_day = next_business_day(current_date)\n",
    "            days_delta = (next_day - current_date).days\n",
    "            days_vector.append(days_delta)\n",
    "        current_date += timedelta(days=1)\n",
    "    return days_vector\n",
    "\n",
    "def calculate_r(start_date: str, settlement_date: str, r_vector, round_to=4) -> float:\n",
    "    r_today = r_vector[-1]\n",
    "    start_date = datetime.strptime(start_date, FORMAT)\n",
    "    settlement_date = datetime.strptime(settlement_date, FORMAT)\n",
    "    days_vector = __create_days_vector(start_date, settlement_date)\n",
    "    \n",
    "    if len(r_vector) == 1:\n",
    "        r_vector = [r_today] * len(days_vector)\n",
    "    \n",
    "    days_in_reference_quarter = np.sum(days_vector)\n",
    "    days_vector = np.array(days_vector)/360\n",
    "    r_vector = np.array(r_vector)/100\n",
    "    \n",
    "    compounded_value = days_vector * r_vector + 1\n",
    "    compounded_value = np.prod(compounded_value) - 1\n",
    "    # print(compounded_value)\n",
    "    return round(compounded_value * 360 * 100 / days_in_reference_quarter, round_to)\n",
    "\n",
    "def get_pv01(rate:np.array, start_date, settlement_date, in_bps=True):\n",
    "    R = calculate_r(start_date, settlement_date , rate)\n",
    "    change = R - calculate_r(start_date, settlement_date, rate-0.01)\n",
    "    print(R)\n",
    "    print(calculate_r(start_date, settlement_date, rate-0.01))\n",
    "    if in_bps:\n",
    "        return change*10000/(100-R)\n",
    "    return change*100/(100-R)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settlement_date = \"19/03/2025\"\n",
    "start_date = datetime.strftime(datetime.strptime(settlement_date, FORMAT) - pd.DateOffset(months=3), FORMAT)\n",
    "\n",
    "R = calculate_r(start_date, settlement_date , [4.82])\n",
    "imm_s3h5 = 100 - R\n",
    "pv_01 = get_pv01(np.array([4.82]), start_date, settlement_date)\n",
    "print(f\"SOFR 3m for settlement date: {settlement_date} (START of contract: {start_date}) : {imm_s3h5} (R={R}) PV01: {round(pv_01, 2)} bps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Function to fetch page content\n",
    "def fetch_page(url):\n",
    "    try:\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "        }\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching page: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to scrape match details\n",
    "def scrape_match_details(url):\n",
    "    page_content = fetch_page(url)\n",
    "    if not page_content:\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(page_content, 'html.parser')\n",
    "\n",
    "    # Example: Extract match details\n",
    "    try:\n",
    "        match_details = {}\n",
    "        match_details['teams'] = [team.text for team in soup.find_all('div', class_='team-name')]\n",
    "        match_details['score'] = soup.find('div', class_='score').text.strip()\n",
    "        match_details['date'] = soup.find('div', class_='date').text.strip()\n",
    "\n",
    "        return match_details\n",
    "    except AttributeError:\n",
    "        print(\"Failed to parse match details. The website structure might have changed.\")\n",
    "        return None\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace this with the URL of the specific match or page on SofaScore\n",
    "    sofascore_url = \"https://www.sofascore.com/football/2024-11-28\"\n",
    "    match_data = scrape_match_details(sofascore_url)\n",
    "\n",
    "    if match_data:\n",
    "        print(\"Match Details:\")\n",
    "        for key, value in match_data.items():\n",
    "            print(f\"{key.capitalize()}: {value}\")\n",
    "    else:\n",
    "        print(\"No match data found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
